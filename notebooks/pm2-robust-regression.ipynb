{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use the same data from earlier this morning and add some error\n",
    "n = 100\n",
    "x = np.arange(1,n).reshape(-1,1)\n",
    "y = np.array([(i**2)+(10*i)*(np.sin(i)+1) for i in x])\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some problem data points\n",
    "noutlier = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By making the number of outliers a variable it is easy to adjust and rerun to see how the number of outliers changes the ability to fit a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.vstack([x,np.random.uniform(0,100,noutlier).reshape(noutlier,1)])\n",
    "y = np.vstack([y,np.random.uniform(0, 8000,noutlier).reshape(noutlier,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be sure to apply the transformation that we found earlier and separate out test and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform y variable\n",
    "y = \n",
    "\n",
    "# Create train and test data sets: x_train, y_train, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) General regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \n",
    "model.fit()\n",
    "print(\"R^2: \",model.score(x_test, y_test))\n",
    "print(\"Slope: \", model.coef_)\n",
    "print(\"Intercept: \", model.intercept_)\n",
    "\n",
    "# Predict on test data\n",
    "pred_test = \n",
    "\n",
    "# Residuals for test data\n",
    "res_test = \n",
    "\n",
    "# Predict on all data (ie. all x)\n",
    "pred = \n",
    "\n",
    "# Residuals for all data\n",
    "res = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot two plots (1 row, two columns) to visualise the results for the test dataset. In the first plot, plot actual data and line fit for test data. In the second plot, plot the residuals for the test data. The functions ```sns.scatterplot()```, ```sns.lineplot()``` may be useful. \n",
    "\n",
    "You may need to reshape the data into the right format, e.g. ```x_test.reshape(-1)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "fig, ax = plt.subplots(1, 2)\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot another two plots (1 row, two columns), this time to visualise the results for the entire dataset. Use ```x```, ```y``` this time instead of ```x_test``` and ```y_test```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "fig, ax = plt.subplots(1, 2)\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to repeat producing our plots for the next 3 sections. Instead of copying out the above code 3 times, write a function that will produce the visualisations you've just done above. Ideally, all variables used within the function should be defined in relation to the arguments of the function (but you can skip this in the interest of time).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_plots(title=None):\n",
    "    \"\"\"\n",
    "    Plot residual and model fit plots. The assumption of outside\n",
    "    function variable names that this function is based on is bad practice.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plots('OLS Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) RANSAC\n",
    "\n",
    "RANSAC: Randomly sample the points over and over again, and pick the sample that best represents the inliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ransac = linear_model.RANSACRegressor()\n",
    "ransac.fit()\n",
    "print(\"R^2: \",ransac.score(x_test, y_test))\n",
    "pred_test = \n",
    "res_test = \n",
    "pred = \n",
    "res = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plots('RANSAC Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Theil-Sen\n",
    "\n",
    "\n",
    "Theil-Sen: Pick out all possible pairs of points, calculate all the slopes and pick the median. Calculate the intercept and choose the median\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theil_sen = linear_model.TheilSenRegressor(random_state=3)\n",
    "theil_sen.fit(x_train, y_train.ravel())\n",
    "print(\"R^2: \",theil_sen.score(x_test, y_test))\n",
    "pred_test = \n",
    "res_test = \n",
    "pred = \n",
    "res = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plots('Theil-Sen Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Huber \n",
    "\n",
    "Huber Regression: Model fit that minimises Huber loss. Huber loss is a mix of squared loss and absolute loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huber = linear_model.HuberRegressor()\n",
    "huber.fit(x_train, y_train.ravel())\n",
    "print(\"R^2: \",huber.score(x_test, y_test))\n",
    "pred_test = \n",
    "res_test = \n",
    "pred = \n",
    "res = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plots('Huber Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R^2 OLS: \",model.score(x_test, y_test))\n",
    "print(\"R^2 RANSAC: \",ransac.score(x_test, y_test))\n",
    "print(\"R^2 Theil-Sen: \",theil_sen.score(x_test, y_test))\n",
    "print(\"R^2 Huber: \",huber.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,y,label='Transformed Data')\n",
    "xseq = np.linspace(0,100,num=100).reshape(-1, 1)\n",
    "plt.plot(xseq,model.predict(xseq),label='OLS')\n",
    "plt.plot(xseq,ransac.predict(xseq),label='RANSAC')\n",
    "plt.plot(xseq,theil_sen.predict(xseq),label='Theil-Sen')\n",
    "plt.plot(xseq,huber.predict(xseq),label='Huber')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,y**2,label='Data')\n",
    "xseq = np.linspace(0,100,num=100).reshape(-1, 1)\n",
    "plt.plot(xseq,model.predict(xseq)**2,label='OLS')\n",
    "plt.plot(xseq,ransac.predict(xseq)**2,label='RANSAC')\n",
    "plt.plot(xseq,theil_sen.predict(xseq)**2,label='Theil-Sen')\n",
    "plt.plot(xseq,huber.predict(xseq)**2,label='Huber')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
