{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Models I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if using jupyterhub\n",
    "# %pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile-Quantile Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 10000 random numbers from a normal distribution with 0 mean and standard deviation 5\n",
    "sample = np.random.normal(0, 5, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the samples to a theoretical normal distribution\n",
    "sm.qqplot(sample,line='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes our data does not look strictly linear. In some cases, we can transform our data so that we can easily apply linear regression. To understand various transforms, we will create a data series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1,100).reshape(-1,1)\n",
    "y = np.array([(i**2)+(10*i)*(np.sin(i)+1) for i in x]) # + np.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(y,line='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data does not look strictly linear, but let's go ahead and fit a linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = \n",
    "model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R^2: \",model.score(x_test, y_test))\n",
    "print(\"Slope: \")\n",
    "print(\"Intercept: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = \n",
    "res_test = \n",
    "\n",
    "plt.subplot(121)\n",
    "plt.scatter(x_test,y_test,label='Data')\n",
    "plt.plot(x_test,pred_test,label='Fit')\n",
    "plt.legend()\n",
    "plt.subplot(122)\n",
    "plt.scatter(x_test,res_test)\n",
    "plt.title(\"Residuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks pretty good! And the coefficient of determiniation is close to 1. Looks like we have a nice model. Let's plot the model for all of the input data (x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = \n",
    "res = \n",
    "\n",
    "plt.subplot(121)\n",
    "plt.scatter(x,pred,label='Fit')\n",
    "plt.scatter(x,y,label='Data')\n",
    "plt.legend()\n",
    "plt.subplot(122)\n",
    "plt.scatter(x,res)\n",
    "plt.title(\"Residuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Look at those residuals. I don't think the model we have obtained is great. Looking at the residuals, the error seems to increase as the value of x increases. This could be a sign of heteroscedasticity, which violates one of our assumptions.\n",
    "\n",
    "Let's try to transform the data (y) and see if this helps make the residuals more normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Reciprocal Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While not very useful for the current example, a reciprocal transforms can be useful for changing the scale of the data if there is a need to make the values more manageable and understandable. It can be particularly useful with data expressed as ratios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_rec = 1/y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,transform_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In nature, various phenomena have been shown to exhibit an exponential relationship. In the physical sciences, the exponential function shows up often enough that when we think about transformations the log transform should come to mind. The log transform is a special case of a change of base transform. From looking at the residuals, the errors are showing an interesting pattern that we want to try and account for in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_log = np.log(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,transform_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(transform_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(x,y):\n",
    "    \"\"\"\n",
    "    1. Takes in the observations (y) and explanatory (x) variable.\n",
    "    2. Separates into training and test data using test size of 0.25 and random state of 5.\n",
    "    3. Generates sklearn.linear_model.LinearRegression model\n",
    "    4. Trains model\n",
    "    5. Predicts on test data\n",
    "    6. Predicts on observations (y)\n",
    "    7. Plots residual and model fit for test data\n",
    "    8. Plots residual and model fit for observations.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    x\n",
    "        Predictors\n",
    "    y \n",
    "        Observations\n",
    "        \n",
    "    Returns\n",
    "    --------\n",
    "    model\n",
    "        sklearn.linear_model.LinearRegression\n",
    "    \"\"\"\n",
    "    x_train, x_test, y_train, y_test = \n",
    "    model = \n",
    "    model.fit()\n",
    "    print(\"R^2: \",)\n",
    "    print(\"Slope: \",)\n",
    "    print(\"Intercept: \",)\n",
    "    pred_test =\n",
    "    res_test =\n",
    "\n",
    "    if(x.shape[1] > 1):\n",
    "        sort_axis = operator.itemgetter(0)\n",
    "        sorted_zip = sorted(zip(x_test[:,1],pred_test), key=sort_axis)\n",
    "        xplt, yplt = zip(*sorted_zip)\n",
    "    else:\n",
    "        xplt = x_test\n",
    "        yplt = pred_test\n",
    "        \n",
    "    plt.subplot(121)\n",
    "    plt.scatter(xplt,y_test,label='Test data')\n",
    "    plt.plot(xplt,yplt,label='Model fit',color='red',linewidth=2)\n",
    "    plt.legend()\n",
    "    plt.subplot(122)\n",
    "    plt.scatter(xplt,res_test)\n",
    "    plt.title(\"Residuals (test data)\")\n",
    "    plt.show()\n",
    "\n",
    "    pred = model.predict(x)\n",
    "    res = pred - y\n",
    "\n",
    "    if(x.shape[1] > 1):\n",
    "        sort_axis = operator.itemgetter(0)\n",
    "        sorted_zip = sorted(zip(x[:,1],pred), key=sort_axis)\n",
    "        xplt, yplt = zip(*sorted_zip)\n",
    "    else:\n",
    "        xplt = x\n",
    "        yplt = pred\n",
    "\n",
    "    plt.subplot(121)\n",
    "    plt.plot(xplt,yplt,label='Fit',color='red',linewidth=2)\n",
    "    plt.scatter(xplt,y,label='Data')\n",
    "    plt.legend()\n",
    "    plt.subplot(122)\n",
    "    plt.scatter(xplt,res)\n",
    "    plt.title(\"Residuals\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case it does not look like a log transform is a good idea. It shifted the skew of the data distribution and did not address the underlying issue with the trend still seen in the residuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Square Root Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a square root transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_sqrt = np.sqrt(y) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_model = make_model(x,transform_sqrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! I would say this looks better. The errors look relatively uniform and centered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative way to do this is via the [preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html) toolkit in scikit-learn. Just for fun, let's make our own square root transformer (which could be used in a scikit-learn pipeline workflow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "transformer = preprocessing.FunctionTransformer(np.sqrt, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.transform(y)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(transformer.transform(y) - transform_sqrt) # to convince ourselves this is yielding the same data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box-Cox Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Box-Cox is a general power transform. The log and square root transforms are specific cases of a Box-Cox transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxcox_transformer = preprocessing.PowerTransformer(method='box-cox', standardize=True).fit(y)\n",
    "boxcox_transformer.lambdas_ # this is the exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_boxcox = boxcox_transformer.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxcoxmodel = make_model(x,y_boxcox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit here is perhaps not as good as the square root transform, but would help us hone in on the correct transform to use if we did not know where to start. When you have time, explore some of the preprocessing transforms that might be of use such as the [quantile](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.quantile_transform.html#sklearn.preprocessing.quantile_transform) transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If power transforms are not sufficient, we can look at introducing additional terms into our linear model and using polynomial regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial = preprocessing.PolynomialFeatures(degree=2)\n",
    "x_poly = polynomial.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polymodel = make_model(x_poly,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it visually looks like the polynomial has a better fit to the data, the residuals show a different pattern. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, based on all the linear models that we have fit to transformed data it seems the one with the square root transform has the best fit and satisfies the assumptions so that we have confidence in using the model. Applying more complex data transformations, via Box-Cox, and using a polynomial to fit the data did not address the underlying issues we sought out to address."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will look at the use of resampling of data. Let's load data on cumulative COVID-19 cases made available by Johns-Hopkins. The data is available on github through the links below.\n",
    "\n",
    "Cumulative global cases of [COVID-19](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series) available [here](https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv) from Johns-Hopkins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile =\n",
    "covid = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aus = covid[covid['Country/Region'] == 'Australia'].drop(columns=['Country/Region','Lat','Long'])\n",
    "aus.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aus.set_index(keys='Province/State',inplace=True)\n",
    "aus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aus = aus.transpose()\n",
    "aus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes! Let's try to sample the data at a more meaningful level. The first thing we need to do is ensure that the dataframe columns are appropriately typed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aus.index =  # change the index to a date index\n",
    "aus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aus.plot() # we can see that the data is showing cumulative counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily =  #difference the rows to get daily counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily['Western Australia'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's resample the daily case count for a weekly case count\n",
    "weekly_summary = \n",
    "weekly_summary['Western Australia'] = \n",
    "weekly_summary.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily['Western Australia'].cumsum().plot() # look at the cumulative counts from daily counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aus['Western Australia'].plot() # look at the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly = \n",
    "weekly['Western Australia'] = # resample the original data to a weekly mean\n",
    "weekly.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By resampling the data, we can reduce the number of data and get a weekly average rather than a daily count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling and fitting a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to our toy example. Let's treat it like a set of timeseries data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['date'] = \n",
    "df['y'] = y\n",
    "df.set_index('date', inplace=True, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.y.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_summary = \n",
    "monthly_summary['y'] = \n",
    "monthly_summary.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_summary.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_summary['date_delta'] = \n",
    "monthly_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newx = np.array(monthly_summary['date_delta']).reshape(-1, 1)\n",
    "month_model = make_model(newx,monthly_summary['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "make_model(newx, np.sqrt(monthly_summary['y']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Fit a model to the cumulative case counts for Western Australia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the COVID-19 data sourced from John Hopkins, try to fit a linear model to the cumulative case counts. Some tasks to consider before fitting a linear model:\n",
    "\n",
    "- What is the time increment to be used?\n",
    "- Will a data transformation be necessary?\n",
    "- Will zero values pose a problem?\n",
    "\n",
    "As you test fitting different models and data transformations, think about what each of one is doing to the data. Does it make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try using a power transform called yeo-johnson, similar to the box-cox, that works with zero valued data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a polynomial of differing orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having tested a few different models, consider :\n",
    "- How well does a linear model fit the cumulative counts?\n",
    "- Does it make sense to fit a model to the cumulative counts? What about the daily counts?\n",
    "- What other strategies could be used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "core05",
   "language": "python",
   "name": "core05"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
